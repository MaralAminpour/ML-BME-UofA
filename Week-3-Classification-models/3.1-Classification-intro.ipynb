{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a664f09-1cb3-4f9b-b798-d01190827bcd",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "This week, we will cover machine learning for classification. First, we will cover some of the basic concepts. Then we will look at some hands-on examples using Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8259e-265d-46eb-bca0-714156a657a8",
   "metadata": {},
   "source": [
    "## What is classification?\n",
    "\n",
    "For a **classification** machine learning problem, we are interesting in predicting which **class** a sample will be in based on one or more features of the sample. Classes sometimes also termed labels. The goal of our model is to predict which class a sample is in. This is a type of supervised learning where we will train our models using labeled data. Examples of classes include \"healthy\" vs \"disease\"; or \"healthy\" vs \"minor disease\" vs \"serious disease\". If we have exactly two classes, then we have a **binary** classification problem. For a binary classification problem, it is common to designate one class as positive (or label 1) and another class as negative (or label 0). If we have more than two classes, then we have a **multiclass** (or **multilabel**) problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9f8d5-9125-4788-970a-40e32ae7c9d1",
   "metadata": {},
   "source": [
    "## Prediction of labeling and prediction of confidence\n",
    "\n",
    "The minimum information that our model needs to provide about each sample is the predicted class. It is often also useful for the model to also provide a confidence for the prediction or predicted probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a895c-045e-4dc1-abeb-e4b138db217c",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "One of the most useful visualizations of the predictions of a classification model is the confusion matrix. This will show the number (or fraction) of the predictions that fall into different sets.\n",
    "\n",
    "For binary classification, we can define four sets. First, we need to select one class to be the \"positive\" class and the other class to be the \"negative\" class. Usually we will use label 0 as the negative class and label 1 and the positive class.\n",
    "\n",
    "True positive (TP): The true and predicted labels are both positive.\n",
    "\n",
    "True negative (TN): The true and predicted labels are both negative.\n",
    "\n",
    "False positive (FP): The true label is negative but the predicted label is positive.\n",
    "\n",
    "False negative (FN): The true label is positive but the predicted label is negative.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/Confusion-Matrix-2.png\" width = \"250\" style=\"float: left;\">\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/confusion-matrix.png\" width = \"250\" style=\"float: right;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820024ce-5c5d-46e2-84a3-354f5f291ee1",
   "metadata": {},
   "source": [
    "Confusion matrices can also be used for multiclass classification, not just binary classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9a9a1-ae9c-4734-981f-59e3d303a07c",
   "metadata": {},
   "source": [
    "## Scoring classification models\n",
    "\n",
    "There are several scores (or metrics) that are useful for evaluating the perfomance of a classification model, and for comparing different classification models.\n",
    "\n",
    "The simplest score is accuracy.\n",
    "\n",
    "accuracy = $\\frac{(TP + TN)}{TP + TN + FP + FN}$\n",
    "\n",
    "However, there is an issue with accuracy. Often, we want to minimize false positives. Or we may want to minimize false negatives.\n",
    "\n",
    "In the biomedical world, the following metrics are commonly used for evaluating binary classification models:\n",
    "\n",
    "sensitivity = true positive rate = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "specificity = true negative rate = $\\frac{TN}{TN + FP}$\n",
    "\n",
    "In the machine learning world, the following related metrics are more commonly used:\n",
    "\n",
    "recall = sensitivity = true positive rate = $\\frac{TP}{TP + FN}$\n",
    "precision = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "[Extend definitions for the multiclass case]\n",
    "\n",
    "Furthermore, the $F_1$ score is a combination of recall and precision, and is often used a single score to evaluate models.\n",
    "\n",
    "$F_1 = 2 \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e808e-f78c-450a-bd6b-495a1a4da870",
   "metadata": {},
   "source": [
    "## Receiver-operator-characteristic (ROC) curves\n",
    "\n",
    "Another technique to evaluate binary classification models are receiver-operator characteristics curves.\n",
    "\n",
    "We need a model that returns a confidence score or has an adjustable decision boundary.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/roc-curve.png\" width = \"300\" style=\"float: right;\">\n",
    "\n",
    "We plot the true positive rate on one axis and the false positive rate on the other axis.\n",
    "\n",
    "After computing the ROC curve, we can calculate the area under the curve (AUC). The AUC can be used as a metric to compare models. With this metric, with a larger AUC are ranked higher than models with a lower AUC. This assumes we are interested in models with a balance between sensitivity and specificity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39296d7f-9804-46c8-b16b-3692a04fb492",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "There are many types of models for classification. Different models will be appropriate for different types of data. The model can be selected by testing the performance of the model on your data, or by experience. In the following notebooks will go through examples using each model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea4c01-f150-44f5-ab9a-927f5fba00a1",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/Perceptron2.png\">\n",
    "\n",
    "The linear perceptron is a simple model for classification. A linear perceptron is simple model that will find a line (or in higher dimensions a plane or hyper-plane) that divides the data into two classes. It can also be used for multiclass problems (see a later notebook).\n",
    "\n",
    "So how can we find the decision function for our dataset? There are various algorithms to do that. We have already introduced the perceptron model before and we will revisit it now.\n",
    "\n",
    "In perceptron model we find the decision function that minimises perceptron\n",
    "criterion. This loss function penalises misclassified samples proportionally to their distance from the decision boundary, which is expressed by the absolute value of the decision function. The perceptron learning algorithm is simple. We will first pick a random sample. If the sample is misclassified we will update the weight vector. The algorithm iterates until convergence. The value eta is the learning rate and is usually set to 1. This algorithm has some disadvantages. It does not always have a unique solution and is not always guaranteed to converge. But it generally works in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ee42e-3b1c-43e4-ab30-290412a27136",
   "metadata": {},
   "source": [
    "## Linear Binary Classification\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/LinearBinaryClassification3.png\">\n",
    "\n",
    "Let's now look in detail how linear binary classification works. The prediction is based on decision function, which is a multivariate linear function.\n",
    "\n",
    "The decision boundary is defined by decision function being equal to zero.\n",
    "\n",
    "If the value of decision function is positive, we will predict label 1. If the value of decision function is negative, we will predict label 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4418682b-6dec-4966-90dd-e90634c25d31",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier\n",
    "\n",
    "The next model we'll look at is the logistic regression classifier. Note that despite the name this is a classification model not a regression model!\n",
    "\n",
    "An advantage of the logistic regression classifier is that the output of the model is a probability.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/LogisticRegression.png\">\n",
    "\n",
    "Logistic regression model allows us to do that. It converts the output of the decision function h to probability of the positive class using sigmoid function. This function squashes the output of decision function into rage [0,1].\n",
    "\n",
    "Probability of label 1 given the feature x is therefore sigmoid of h(x), plotted here using the red solid line. The probability of label 0 for the same feature is 1 minus probability of label 1. It is plotted using the blue dotted line.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/CrossEntropy2.png\">\n",
    "\n",
    "So how do we fit the logistic regression model? We minimise cross entropy loss. Letâ€™s consider a single sample with index i and see what cross entropy loss means for this sample. The probability pi for this sample is the probability of the class one.\n",
    "\n",
    "If the label for this sample is 1, the penalty will be equal to minus logarithm pi. If pi is one, it will result in zero penalty. If $p_i$ is close to zero, it will result in large penalty. The loss function is therefore forcing the probability to 1 for samples with label 1.\n",
    "\n",
    "If the label for this sample is 0, the penalty will be equal to minus logarithm 1\n",
    "$p_i$. If pi is zero, the penalty is zero as well. If $p_i$ is close to 1, it will result in large penalty. For samples with label 0 the loss function forces probability to zero as well.\n",
    "\n",
    "We can therefore see that minimisation of cross entropy ensures that probabilities $p_i$ are similar to labels $y_i$. The solution is found using numerical methods and in this case, the convergence is guaranteed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba17139-a8f1-471c-9718-856a5a3d6be2",
   "metadata": {},
   "source": [
    "## Support Vector Classifier \n",
    "\n",
    "Next we'll take a look at the support vector classifier (SVC). This is also often called support vector machine (SVM).\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/LinearlySeparableDataset.png\" width = \"300\" style=\"float: right;\">\n",
    "\n",
    "- First, let's assume we have a linearly separable dataset\n",
    "- All 3 decision boundaries result in accuracy = 1\n",
    "- Which boundary is likely to generalise well?\n",
    "- The red boundary is most likely to generalise well\n",
    "\n",
    "Linearly separable datasets can be perfectly separated by a linear decision boundary and we can achieve classification accuracy 1. In our example of diagnosis of heart failure, this is the case for healthy patients and patients with severe heart failure.\n",
    "\n",
    "There are many decision boundaries with accuracy 1 for separable datasets. So how do we choose the one that is most likely to generalise well?\n",
    "\n",
    "The red boundary seem to be the best because it is far from the samples unlike the other two.\n",
    "\n",
    "**Large margin classifier (hard margin)**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/HardMargin.png\" width = \"400\" style=\"float: right;\">\n",
    "\n",
    "With a large margin classifier, the decision boundary is\n",
    "- as far as possible from the samples\n",
    "- determined by samples on the margins - **support vectors**\n",
    "\n",
    "Support vector classifier is a large margin classifier, which means that it searches for a decision boundary that is as far as possible from the samples.\n",
    "\n",
    "The decision boundary is determined by samples that lie on the margins and are called support vectors, here denoted by pink circles.\n",
    "\n",
    "**Large margin classifier (soft margin)**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/SoftMargin.png\" width = \"400\" style=\"float: right;\">\n",
    "\n",
    "With a soft margin classifier, the decision boundary\n",
    "- minimises margin violations\n",
    "- is determined by samples on or inside the margins or on the wrong side of the decision boundary - **support vectors**\n",
    "\n",
    "Large margin classifiers can be generalised to non-separable datasets by minimising the margin violations. The decision boundary is again determined by support vectors, which lie on or inside the margin or on the wrong side of the decision boundary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0dab8c-929d-431d-8959-4c215d03fe94",
   "metadata": {},
   "source": [
    "Now let's look at an example using a support vector classifier\n",
    "\n",
    "# Support vector classification\n",
    "\n",
    "In this notebook we will explore Support Vector Classifier (SVC). Linear binary SVC is very similar to the perceptron and logistic regression in a sense that it finds the optimal hyperplane to separate two classes. These methods, however, have different objectives through which they decide what is the optimal decision boundary.\n",
    "\n",
    "There are three different SVC classifiers in `sklearn` library:\n",
    "1. `LinearSVC` implements linear classifier optimised for performance but does not support the kernel trick\n",
    "2. `SVC` implements SVC with kernel trick. Setting `kernel='linear'` produces the same result as `LinearSVC` but is less efficient in terms of computational time. Setting `kernel='rbf'` produces non-linear classifier with Gaussian kernel.\n",
    "3. `SGDclassifier` implements various classifiers that are optimised using stochastic gradient descent. Its default setting for loss function is `loss='hinge'` which is another implementation of a linear SVC.\n",
    "\n",
    "SVC result also depends on hyperparameter `C` which controls the width of the margin and regularises the decision function. Larger `C` means smaller margin, less regularisation, and closer approximation of hard margin objective. Smaller `C` means larger margin, and smoother boundary for non-linear SVC. Note, that `C` has an opposite role to the parameter `alpha` that we used for penalised regression (e.g. `Ridge`). This is because it multiplies the data term rather than the penalty term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad91a81-264f-46c6-80b0-5c8761eae577",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/Decision-tree.png\" width = \"400\" style=\"float: right;\">\n",
    "\n",
    "Type of graph\n",
    "\n",
    "- Nodes (questions)\n",
    "- Edges (binary choices\n",
    "\n",
    "Sets of tests that are hierarchically organised. Each test is a _weak learner_.\n",
    "\n",
    "Advantages of decision trees:\n",
    "\n",
    "- Easy to interpret\n",
    "- Able to handle both numerical and categorical data\n",
    "- Able to handle multi-class problems\n",
    "- Requires little data preparation (e.g. no normalization)\n",
    "- Can be used for both classification and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3470eb95-ea9a-4327-a4fe-c882982de90e",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "\n",
    "Ensemble of decision trees\n",
    "\n",
    "- Increases randomisation by restricting each tree node's choice of optimal feature from a subset of the total feature space\n",
    "- Further decorrelates predictive models\n",
    "- Further decreases model variance\n",
    "- Increases stability against feature noise and thus chance of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa67c6-4605-4ec3-ae1b-0f4f6f71d6f7",
   "metadata": {},
   "source": [
    "## Extra techniques\n",
    "\n",
    "Finally we will cover examples of some additional techniques that are important for classification problems:\n",
    "\n",
    "1. Encoding classes\n",
    "2. One-hot encoding\n",
    "3. Creating training and test sets\n",
    "4. Handling unbalance datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cbee22-ca0d-45d4-840d-2cf08a0d0865",
   "metadata": {},
   "source": [
    "## Example - The Titanic Kaggle challenge: A case study for classification\n",
    "\n",
    "Titanic Kaggle Challenge is a competition where you'll use data to predict who could've survived the infamous Titanic disaster.\n",
    "\n",
    "Classification \"survived\" or \"not survived\"\"\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-3-Classification-models/imgs/x.png' width=500px align=\"center\">\n",
    "\n",
    "Let's explore machine learning with a fun example from Kaggle, a competition site owned by Google. These contests can be for giggles, cash prizes, or even a job offer sometimes! The Titanic Kaggle Challenge is known as one of the classic examples for learning classification in a hands-on way.\n",
    "\n",
    "One beginner's challenge is based on the Titanic disaster, a famous shipwreck that happened on April 15, 1912. The ship, thought to be unsinkable, hit an iceberg and sank, sadly causing 1502 out of 2224 people onboard to lose their lives because there weren't enough lifeboats.\n",
    "\n",
    "But it's not just about guessing who made it. It's about deeply exploring the data, finding patterns, and understanding how different factors might have affected survival rates. It poses questions like 'Did socioeconomic status influence survival rates?' and 'What was the impact of the \"women and children first\" policy? Was the 'women and children first' policy strictly followed?'\n",
    "\n",
    "Here's the interesting part: it seems that some people were more likely to survive than others. The challenge asks us to figure out who these folks were, using data like their names, ages, genders, and social classes.\n",
    "\n",
    "We get a file with details about 891 passengers, including whether they survived or not. We'll use this data to teach our machine to make smart guesses.\n",
    "\n",
    "But the real test comes with another file, this one has information on 418 passengers, but doesn't tell us if they survived. That's where our machine's predictions come in!\n",
    "\n",
    "Suggested tutorial about Kaggle's titanic challange: [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic)\n",
    "\n",
    "You can follow Chris White's tutorial on this subject through this Jupyter notebook: [01-intro-classification.ipynb](https://colab.research.google.com/github/ualberta-rcg/python-machine-learning/blob/main/notebooks/01-intro-classification.ipynb#scrollTo=Gd80ekh_zQu4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b1e67-92c6-4407-9fcb-7c36d7278eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
