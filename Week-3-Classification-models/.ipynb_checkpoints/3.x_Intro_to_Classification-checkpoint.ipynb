{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a664f09-1cb3-4f9b-b798-d01190827bcd",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "This week, we will cover machine learning for classification. First, we will cover some of the basic concepts. Then we will look at some hands-on examples using Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b8259e-265d-46eb-bca0-714156a657a8",
   "metadata": {},
   "source": [
    "## What is classification?\n",
    "\n",
    "For a **classification** machine learning problem, we are interesting in predicting which **class** a sample will be in based on one or more features of the sample. Classes sometimes also termed labels. The goal of our model is to predict which class a sample is in. This is a type of supervised learning where we will train our models using labeled data. Examples of classes include \"healthy\" vs \"disease\"; or \"healthy\" vs \"minor disease\" vs \"serious disease\". If we have exactly two classes, then we have a **binary** classification problem. For a binary classification problem, it is common to designate one class as positive (or label 1) and another class as negative (or label 0). If we have more than two classes, then we have a **multi-class** problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d9f8d5-9125-4788-970a-40e32ae7c9d1",
   "metadata": {},
   "source": [
    "## Prediction of labeling and prediction of confidence\n",
    "\n",
    "The minimum information that our model needs to provide about each sample is the predicted class. It is often also useful for the model to also provide a confidence for the prediction or predicted probabilities for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79a895c-045e-4dc1-abeb-e4b138db217c",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "One of the most useful visualizations of the predictions of a classification model is the confusion matrix. This will show the number (or fraction) of the predictions that fall into different sets.\n",
    "\n",
    "For binary classification:\n",
    "\n",
    "True positive:\n",
    "True negative:\n",
    "False positive:\n",
    "False negative:\n",
    "\n",
    "[Show images of confusion matrices here.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd9a9a1-ae9c-4734-981f-59e3d303a07c",
   "metadata": {},
   "source": [
    "## Scoring classification models\n",
    "\n",
    "There are several scores (or metrics) that are useful for evaluating the perfomance of a classification model, and for comparing different classification models.\n",
    "\n",
    "The simplest score is accuracy.\n",
    "\n",
    "[Define accuracy]\n",
    "[Define accuracy for ]\n",
    "\n",
    "However, there is an issue with accuracy. Often, we want to minimize false positives. Or we may want t\n",
    "\n",
    "[Examples of cases where you would want to minimize false positives or false negatives]\n",
    "\n",
    "In the biomedical world, the following metrics are commonly used for evaluating binary classification models:\n",
    "\n",
    "[Define sensitivity]\n",
    "[Define specificity]\n",
    "\n",
    "In the machine learning world, the following related metrics are more commonly used:\n",
    "\n",
    "[Define recall]\n",
    "[Define precision]\n",
    "[Extend definitions for the multiclass case]\n",
    "\n",
    "Furthermore, the F1-score is combination of recall and precision, and is often used a single score to evaluate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e808e-f78c-450a-bd6b-495a1a4da870",
   "metadata": {},
   "source": [
    "## Receiver-operator-characteristic (ROC) curves\n",
    "\n",
    "Another technique to evaluate binary classification models are receiver-operator characteristics curves.\n",
    "\n",
    "We need a model that returns a confidence score or has an adjustable decision boundary.\n",
    "\n",
    "We plot the true positive rate (or ...) on one axis and the true negative rate (or ...) on the other axis. Then we plot...\n",
    "\n",
    "[Show curve examples]\n",
    "\n",
    "After computing the ROC curve, we can calculate the area under the curve (AUC). The AUC can be used as a metric to compare models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39296d7f-9804-46c8-b16b-3692a04fb492",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "There are many types of models for classification. Different models will be appropriate for different types of data. The model can be selected by testing the performance of the model on your data, or by experience. In the following notebooks will go through examples using each model.\n",
    "\n",
    "### Perceptron\n",
    "\n",
    "### Logistic Regression Classifier\n",
    "\n",
    "### Support Vector Classifier\n",
    "\n",
    "#### Non-linear SVC with kernels\n",
    "\n",
    "### Decision Tree Classifier\n",
    "\n",
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daa67c6-4605-4ec3-ae1b-0f4f6f71d6f7",
   "metadata": {},
   "source": [
    "## Extra techniques\n",
    "\n",
    "Finally we will cover examples of some additional techniques that are important for classification problems:\n",
    "\n",
    "1. Encoding classes\n",
    "2. One-hot encoding\n",
    "3. Creating training and test sets\n",
    "4. Handling unbalance datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
