{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-label classification\n",
    "\n",
    "In this notebook we will consider three classes of patients:\n",
    "* Healthy: Label 0\n",
    "* Mild Heart Failure: Label 1\n",
    "* Severe Heart Failure: Label 2\n",
    "\n",
    "We will consider two features - **EF** and **GLS**.\n",
    "\n",
    "### Libraries and dataset\n",
    "Run the code bellow to load the libraries, dataset, create the feature matrix `X` and label vector `y` and finally plot the dataset. Note that we updated the function `PlotData` to deal with 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/heart_failure_data_complete.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# read fine into a dataframe object\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/heart_failure_data_complete.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# convert dataframe to numpy array\u001b[39;00m\n\u001b[1;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/heart_failure_data_complete.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# read fine into a dataframe object\n",
    "df = pd.read_csv('datasets/heart_failure_data_complete.csv')\n",
    "# convert dataframe to numpy array\n",
    "data = df.to_numpy()\n",
    "# Create feature matrix with EF and GLS\n",
    "X = data[:,[1,2]]\n",
    "X = StandardScaler().fit_transform(X)\n",
    "# Create label vector \n",
    "y = data[:,0]\n",
    "# print properties\n",
    "print('Feature matrix X dimensions: ', X.shape)\n",
    "print('Target vector y dimensions: ', y.shape)\n",
    "print('Labels: ', np.unique(y))\n",
    "\n",
    "def PlotData(X,y):\n",
    "    # plot class 0\n",
    "    plt.plot(X[y==0,0],X[y==0,1],'bo',alpha=0.75,markeredgecolor='k',label = 'Healthy')\n",
    "    # plot class 1\n",
    "    plt.plot(X[y==1,0],X[y==1,1],'rd',alpha=0.75,markeredgecolor='k',label = 'Mild HF')\n",
    "    # plot class 2\n",
    "    plt.plot(X[y==2,0],X[y==2,1],'g^',alpha=0.75,markeredgecolor='k',label = 'Severe HF')\n",
    "    \n",
    "    # annotate the plot\n",
    "    plt.title('Diagnosis of Heart Failure')\n",
    "    plt.xlabel('EF')\n",
    "    plt.ylabel('GLS')\n",
    "    plt.legend()\n",
    "\n",
    "# call the function to plot the dataset\n",
    "PlotData(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "The cell bellow contains some of the functions that we have created in the previous notebook and which can be reused for multilabel classification. These functions are\n",
    "* `PlotClassification`\n",
    "* `PlotProbabilities`\n",
    "* `Accuracy_CV`\n",
    "\n",
    "Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotClassification(model,X,y):\n",
    "\n",
    "    # Create an 1D array of samples for each feature\n",
    "    x1 = np.linspace(-2.5, 2, 1000) \n",
    "    x2 = np.linspace(-3, 3.5, 1000).T # note the transpose\n",
    "    # Creates 2D arrays that hold the coordinates in 2D feature space\n",
    "    x1, x2 = np.meshgrid(x1, x2) \n",
    "    # Flatten x1 and x2 to 1D vector and concatenate into a feature matrix\n",
    "    Feature_space = np.c_[x1.ravel(), x2.ravel()] \n",
    "\n",
    "    # Predict labels for the whole feature space    \n",
    "    y_pred = model.predict(Feature_space)\n",
    "    # Resahpe to 2D\n",
    "    y_pred = y_pred.reshape(x1.shape)\n",
    "    # Plot using contourf\n",
    "    plt.contourf(x1, x2, y_pred, cmap = 'summer')\n",
    "    \n",
    "    # Plot data\n",
    "    PlotData(X,y)\n",
    "\n",
    "def PlotProbabilities(model,X,y,label=1):\n",
    "\n",
    "    # Create an 1D array of samples for each feature\n",
    "    x1 = np.linspace(-2.5, 2, 1000) \n",
    "    x2 = np.linspace(-3, 3.5, 1000).T # note the transpose\n",
    "    # Creates 2D arrays that hold the coordinates in 2D feature space\n",
    "    x1, x2 = np.meshgrid(x1, x2) \n",
    "    # Flatten x1 and x2 to 1D vector and concatenate into a feature matrix\n",
    "    Feature_space = np.c_[x1.ravel(), x2.ravel()] \n",
    "\n",
    "    # Predict labels for the whole feature space    \n",
    "    proba = model.predict_proba(Feature_space)\n",
    "    # Select the class\n",
    "    p = proba[:,label]\n",
    "    # Resahpe to 2D\n",
    "    p = p.reshape(x1.shape)\n",
    "    # Plot using contourf\n",
    "    plt.contourf(x1, x2, p, cmap = 'summer')\n",
    "    \n",
    "    # Plot data\n",
    "    PlotData(X,y)\n",
    "    \n",
    "def Accuracy_CV(model,X,y):\n",
    "    scores = cross_val_score(model,X,y)\n",
    "    print('Accuracy CV: ',round(scores.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and plot the model\n",
    "We will first fit the logistic regression model to the data. Run the cell bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 1:** Plot the classification labels using `PlotClassification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotClassification(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2:** Plot probabilities for all three classes in the same figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,3.5))\n",
    "classes = ['Healthy','Mild Heart Failure', 'Severe Heart Failure']\n",
    "for i in range(3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    PlotProbabilities(model,X,y,label=i)\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "**Activity 3:** Evaluate cross-validated accuracy of the model using `Accuracy_CV`. Is the performance good? To see whether accuracy is reliable measure of performance, calculate the number of samples in each class. Is the dataset balanced?\n",
    "\n",
    "**Answer:** Accuracy 0.89 is quite high, however the dataset is not balanced. We therefore need to further analyse the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy\n",
    "Accuracy_CV(model,X,y)\n",
    "\n",
    "# check for class imbalance\n",
    "print('Number of samples of class 0: ', y[y==0].shape[0])\n",
    "print('Number of samples of class 1: ', y[y==1].shape[0])\n",
    "print('Number of samples of class 2: ', y[y==2].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall\n",
    "\n",
    "The function `Recall_CV` calculates different type of recalls that help us analyse the performance of the multilabel classifier. These can be set by parameter `average`:\n",
    "\n",
    "* `average=None` will return recall for each class. We can find out how well the classifier indentifies each class.\n",
    "* `average=macro` will return recall average over the classes. This measure is sensitive to the performance of individual classes irrespective of their sizes.\n",
    "* `average=micro` will return recall averaged over the samples, e.g. the recall is calculated globally by counting the total true positives, false negatives and false positives. This measure is not very sensitive to the classes of small sizes.\n",
    "\n",
    "**Activity 4**: Calculate different types of recalls by calling the function `Recall_CV`. What can you tell about the performance of the classifier for different classes? How do the different average recalls compare to the accuracy score?\n",
    "\n",
    "**Answer:** Recall is very low for class 2. This is better reflected in average recall over all classes `macro`, which dropped to 0.79 as a result. Setting `micro` returns result similar to accuracy 0.89. The class imballance therefore affected the accuracy measure, that did not properly reflect the poor performance of the classifier to detect patients with severe heart failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Recall_CV(model,X,y):\n",
    "    # predict labels using cross-validation\n",
    "    y_pred = cross_val_predict(model,X,y)\n",
    "    \n",
    "    # calculate recalls for all classes\n",
    "    recalls = recall_score(y,y_pred,average=None)\n",
    "    print('Recalls for all classes: ', np.around(recalls,2))\n",
    "    \n",
    "    # calculate recall averaged over classes\n",
    "    mean_recall_macro = recall_score(y,y_pred,average='macro')\n",
    "    print('Average Recall macro: ', np.around(mean_recall_macro,2))\n",
    "    \n",
    "    # calculate recall averaged over samples\n",
    "    mean_recall_micro = recall_score(y,y_pred,average='micro')\n",
    "    print('Average Recall micro: ', np.around(mean_recall_micro,2))\n",
    "\n",
    "# Calculate recalls\n",
    "Recall_CV(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "The code bellow calculate and plots the confusion matrix. Run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels using cross-validation\n",
    "y_pred = cross_val_predict(model, X, y, cv=5)\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y, y_pred);\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.matshow(cm, cmap='gray')\n",
    "plt.xlabel('Predicted labels', fontsize = 16)\n",
    "plt.ylabel('True labels', fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 5:** Set the diagonal to zero and describe the main sources of misclassification.\n",
    "\n",
    "**Answer:** The main sources of misclassification are\n",
    "* Mild heart failure diagnosed as healthy\n",
    "* Severe heart failure diagnosed as mild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set diagonal to zero\n",
    "np.fill_diagonal(cm, 0)\n",
    "\n",
    "# Plot matrix\n",
    "plt.matshow(cm, cmap='gray')\n",
    "plt.xlabel('Predicted labels', fontsize = 16)\n",
    "plt.ylabel('True labels', fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Balanced multi-label classification (optional)\n",
    "\n",
    "One way to deal with class imbalance is to increase the weight of the samples of smaller classes in the classification loss. For `LogisticRegression` this can be done by setting `class_weight='balanced'`, which will weight the sample inversly to the class size, this giving equal importance to each class irrespective of its size. \n",
    "\n",
    "In this exercise you will fit the logistic regression with class weighting and analyse the performance of the balanced model.\n",
    "\n",
    "### Task 1: Fit and plot the balanced model\n",
    "\n",
    "Fit the logistic regression with `class_weight='balanced'` and plot the classification boundaries/labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the balanced logistic regression model\n",
    "model2 = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# fit the model\n",
    "model2.fit(X,y)\n",
    "\n",
    "# plot classification\n",
    "PlotClassification(model2,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Accuracy\n",
    "Calculate the cross-validated accuracy of the balanced model. Was it affected by the change in weighting of the samples?\n",
    "\n",
    "**Answer:** Yes, the accuracy dropped from 0.89 to 0.83."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CV accuracy\n",
    "Accuracy_CV(model2,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Recall\n",
    "\n",
    "Calculate different types of cross-validated recalls. What has change in the performance of the classifier compared to the unballanced version?\n",
    "\n",
    "**Answer:** There is now higher performance for the smallest class - Severe HF, which improved from 0.5 to 0.83. Hovewer this is at the expense of the mild HF which decreased from 0.88 to 0.65. Average recall over all classes increased from 0.79 to 0.82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_CV(model2,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Confusion matrix\n",
    "Calculate and plot the confusion matrix to identify main types of misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels using cross-validation\n",
    "y_pred = cross_val_predict(model2, X, y, cv=5)\n",
    "\n",
    "# calculate confusion matrix\n",
    "cm = confusion_matrix(y, y_pred);\n",
    "print('Confusion matrix: ')\n",
    "print(cm)\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.matshow(cm, cmap='gray')\n",
    "plt.xlabel('Predicted labels', fontsize = 16)\n",
    "plt.ylabel('True labels', fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set diagonal to zero\n",
    "np.fill_diagonal(cm, 0)\n",
    "\n",
    "# Plot matrix\n",
    "plt.matshow(cm, cmap='gray')\n",
    "plt.xlabel('Predicted labels', fontsize = 16)\n",
    "plt.ylabel('True labels', fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** The main types of misclassifications are:\n",
    "* Mild HF classified as Severe HF (12 samples)\n",
    "* Mild HF classified as Healthy (5 samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
