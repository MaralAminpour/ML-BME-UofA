{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrFflxUGUk1B1wuy2pv3nf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaralAminpour/ML-BME-UofA/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YFeadv2AOqk"
      },
      "outputs": [],
      "source": [
        "I apologize for that oversight. Here's the breakdown with the formulas placed within the `$$` delimiters:\n",
        "\n",
        "---\n",
        "\n",
        "Alright, I'll provide a concise breakdown with the math included:\n",
        "\n",
        "**Kernel Basics**:\n",
        "A kernel is a function that computes the similarity between two data points, often without having to explicitly transform them into another space.\n",
        "\n",
        "**Mathematically Defined**:\n",
        "A kernel is represented as:\n",
        "$$ K(x, y) = \\langle f(x), f(y) \\rangle $$\n",
        "Where:\n",
        "- \\( K \\) is the kernel function.\n",
        "- \\( x, y \\) are data points.\n",
        "- \\( f \\) is a function that maps data points into another space.\n",
        "- \\( \\langle . , . \\rangle \\) denotes the dot product.\n",
        "\n",
        "**Intuition**:\n",
        "To compute the similarity between \\( x \\) and \\( y \\), one approach is to first map them to a new space using \\( f \\) and then compute their dot product. However, this can be computationally heavy, especially if the space is of high dimension. The kernel provides a shortcut, letting us compute this dot product directly, without explicitly performing the mapping, making the process more efficient.\n",
        "\n",
        "**Example**:\n",
        "Given vectors \\( x = (x_1, x_2, x_3) \\) and \\( y = (y_1, y_2, y_3) \\), for a specific function \\( f \\):\n",
        "$$ f(x) = (x_1x_1, x_1x_2, x_1x_3, x_2x_1, x_2x_2, x_2x_3, x_3x_1, x_3x_2, x_3x_3) $$\n",
        "The kernel is defined as:\n",
        "$$ K(x, y) = \\langle x, y \\rangle^2 $$\n",
        "This computes the square of the dot product directly.\n",
        "\n",
        "Using the provided vectors, \\( x = (1, 2, 3) \\) and \\( y = (4, 5, 6) \\):\n",
        "By expanding the polynomial kernel, the result is:\n",
        "$$ K(x, y) = (1*4 + 2*5 + 3*6)^2 = 32^2 = 1024 $$\n",
        "This direct computation is simpler and faster compared to the expanded form.\n",
        "\n",
        "**Kernel's Power**:\n",
        "Kernels have the capability to represent computations even in infinite dimensions. This becomes particularly invaluable when the transformation \\( f(x) \\) might be complex or exists in an infinite-dimensional space, as kernels offer an efficient way to compute the similarity.\n",
        "\n",
        "**Relation to SVM**:\n",
        "In Support Vector Machines (SVM), the aim is to discover a hyperplane that optimally separates the data. The SVM's decision function is represented as:\n",
        "$$ y = w \\cdot \\phi(x) + b $$\n",
        "Here, \\( \\phi \\) denotes the transformation to another space. The kernel becomes an essential tool in SVM, especially when data isn't linearly separable in its original form but might be after the transformation. Explicitly calculating this transformation can be expensive, thus the kernel's utility in simplifying the process.\n",
        "\n",
        "**Similarity Intuition**:\n",
        "The dot product \\( \\langle \\phi(x), \\phi(y) \\rangle \\) calculates the projection of \\( \\phi(x) \\) onto \\( \\phi(y) \\). In essence, it indicates the extent of overlap or similarity that exists between the two data points in their transformed space."
      ]
    }
  ]
}