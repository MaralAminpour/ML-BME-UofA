{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207b2f56-7d54-4fc2-b864-9cec3fc0d65c",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "\n",
    "Let's look at the following questions:\n",
    "\n",
    "1. What is machine learning?\n",
    "\n",
    "2. How do we do machine learning?\n",
    "\n",
    "3. What are some of the challenges and issues we need to consider when doing machine learning?\n",
    "\n",
    "4. What are some of the biomedical applications of machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500ccc5-8000-4ac3-a36e-194f83ed7905",
   "metadata": {},
   "source": [
    "## 1. What is machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f55d70c-e849-4c63-8805-2da11d17cd1a",
   "metadata": {},
   "source": [
    "### AI vs Machine Learning vs Deep Learning\n",
    "\n",
    "Artificial Intelligence is the broader umbrella under which Machine Learning and Deep Learning come. And you can also see in the diagram that even deep learning is a subset of Machine Learning. So all three of them AI, machine learning and deep learning are just the subsets of each other. So let us move on and understand how exactly they are different from each other.\n",
    "\n",
    "\"Artificial Intelligence is a technique that allows machines to act like humans by replicating their behavior and nature.\"\n",
    "\n",
    "“Machine Learning is a subset of artificial intelligence. It allows the machines to learn and make predictions based on its experience(data)“\n",
    "\n",
    "“Deep learning is a particular kind of machine learning that achieves great power and flexibility by learning to represent the world as nested hierarchy of concepts or abstraction”\n",
    "\n",
    " <img src='https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/AI-vs-ML-vs-Deep-Learning.png' width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d927678-305d-42d4-a996-1c990ca2d697",
   "metadata": {},
   "source": [
    "### What is machine learning?\n",
    "\n",
    "You started with some data sets, some data. And you fed it to some magical machine learning algorithm and derive intelligence.   \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/ML_pipline.png' width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80dc40-e2ad-44a2-b480-a74160c7ece7",
   "metadata": {},
   "source": [
    "### Goal of machine learning\n",
    "\n",
    "The goal of machine learning is most often to create a *model* that makes a *prediction*. The model is a mathematical function that takes input (which is some information that we can measure or observe about samples) and returns a prediction. Usually we train our model by providing it with samples where we already know the correct answer (*training data*); this type of machine learning is called _supervised learning_. But ideally we want our model to return good predictions even for new or unseen data. Sometimes we will use machine learning just to identify patterns in data; this type of machine learning is called _unsupervised learning_. Machine learning is often considered a type of Artificial Intelligence (AI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa041b-f6d3-4a28-a178-753309452523",
   "metadata": {},
   "source": [
    "### Supervised vs. unsupervised machine learning\n",
    "\n",
    "When we do _supervised learning_ we have some training data for which we already know the answers: the true class of the data (or at least the class of the data that is assigned by the best method available), or the true value of some quantivative value. Most of this course will cover supervised learning.\n",
    "\n",
    "When we do _unsupervised learning_ we don't have answers available (or at least we analyze the data as if the answers are unavailable). Most commonly we do this by _clustering_, where we apply a method to divide the data into subsets (called clusters). We will discuss clustering during Week 5. [Is PCA/ICA also considered unsupervised learning?]\n",
    "\n",
    "There are also approaches where we combine supervised learning with unsupervised learning (*semi-supervised learning*).\n",
    "\n",
    "Another kind of machine learning is *reinforcement learning*, where the system (or agent) interacts with its environment and receives rewards or punishments based on its responses, and learns through that process.\n",
    "\n",
    "We won't be covering semi-supervised or reinforcement learning in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd283c7-9ca5-4a34-86db-7686730be2f5",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/SupervisedLearning.png\" width = \"400\" style=\"float: right;\">\n",
    "\n",
    "#### Example: Supervised learning\n",
    "\n",
    "Diagnosis of heart failure. Here we recorded two measurements of patient heart function and have each patient labeled in two classes: \"healthy\" or \"heart failure\". The goal of machine learning is to generate a model that predicts the patient class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a59b698-8dd5-40e0-a1f2-8b83d6d9f93b",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/Biopsy.png\" width = \"350\" style=\"float: right;\">\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/BreastCancerClustering.png\" width = \"350\" style=\"float: right;\">\n",
    "\n",
    "#### Example: Unsupervised learning (clustering)\n",
    "\n",
    "Diagnosis of breast cancer. Here we have two features describing cells in a biopsy sample. The goal is to learn if there is a structure in the dataset, without considering the diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30576792-d5f7-47ed-aa11-a2843877c38f",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/BrainMRI.png\" width = \"350\" style=\"float: right;\">\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/MRIClustering.png\" width = \"350\" style=\"float: right;\">\n",
    "\n",
    "#### Example: Unsupervised learning (clustering)\n",
    "\n",
    "Classification of brain tissues. Here we have two features describing pixels in a brain MRI. The goal is to segment the brain into 3 types of regions: WM (white matter), GM (gray matter) and CSF (cerebro-spinal fluid)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d98cb1-0f57-4eed-98c9-4baf1f3555f2",
   "metadata": {},
   "source": [
    "## 2. How do we do machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967c2807-d805-4747-8bc9-489ded5a61af",
   "metadata": {},
   "source": [
    "### The Machine Learning Process\n",
    "\n",
    "When we do machine learning, we normally follow a protocol consisting of the following steps.\n",
    "\n",
    "1. Define the problem\n",
    "\n",
    "- This can be difficult. What are we trying to achieve? What are we trying to predict?\n",
    "\n",
    "2. Get the data & prepare the data & clean the data\n",
    "\n",
    "- This is often connected with the problem definition step, because knowing about the data helps clarify what we can do with it\n",
    "\n",
    "- Often the most tedious and time consuming step\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/ML_Algorithm.png' width=400px align=\"right\">\n",
    "\n",
    "3. Exploratory data analysis and visualization\n",
    "\n",
    "4. Feature selection and extraction\n",
    "\n",
    "5. Create training, validation and test sets\n",
    "\n",
    "6. Select model type and optimization algorithm\n",
    "\n",
    "- Setting up one or more machine learning pipelines\n",
    "\n",
    "7. Train the model\n",
    "\n",
    "- Feed the algorithm data\n",
    "\n",
    "8. Test & evaluate the model\n",
    "\n",
    "- Maybe we need to go back and select a different algorithm to work with?\n",
    "\n",
    "9. Select the best model\n",
    "\n",
    "- The definition of \"best\" depends on the type of problem, the type of data, and our goals\n",
    "\n",
    "10. Predict\n",
    "\n",
    "- Use the model to make predictions based on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce68799-071a-4812-8d19-40a7be9cd5e0",
   "metadata": {},
   "source": [
    "#### Step 1. Define the problem\n",
    "\n",
    "It is very important to understand and describe what exactly we are trying to predict. The classes or values we are trying to predict are called our targets.\n",
    "\n",
    "Are we trying predict discrete *classes* (or *labels*)? For example, does a patient have a disease or not? This is a *classification* problem. If we have two classes, it is a _binary classification_ problem. Sometime we are interested in a _multiclass_ problem, where we want to assign three or more classes.\n",
    "\n",
    "On the other hand, sometimes we are trying to predict a continuous numerical value, for example what is the patients expected survival time? Then we have _regression_ problem.\n",
    "\n",
    "We will talk about classification in Week 3 and regression Week 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe4f0e-66e3-47d9-bba5-5b79401d3295",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/Classification.png\" width = \"600\" style=\"float: right;\">\n",
    "\n",
    "#### Example: Classification\n",
    "\n",
    "Diagnosis of heart failure. Here we recorded two measurements of patient heart function and have each patient labeled in two classes: \"healthy\" or \"heart failure\". The goal of machine learning is to generate a model that predicts the patient class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bffa005-6c36-4e58-8ff3-472051d75954",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/Regression.png\" width = \"600\" style=\"float: right;\">\n",
    "\n",
    "#### Example: Regression\n",
    "\n",
    "Prediction of brain volume. Here we are trying to predict the brain volumes (measured from MRI scans) for preterm babies from gestational age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f53e7-d5e2-474d-bc1f-9f268d121882",
   "metadata": {},
   "source": [
    "#### Step 2. Prepare the data\n",
    "\n",
    "This is often the most time consuming step of any machine learning project!\n",
    "\n",
    "Usually, we will need to preprocess the data so that it is in a format suitable for the type of machine learning we want to do. Sometimes we need to remove missing or low quality samples from the data, or handle some of the data in a special way.\n",
    "\n",
    "Another type of data preparation that is sometimes useful is _data augmentation_. This is particularly important when we have a small amount of data. For example, if we have a set images (assuming there is no natural orientation), we could rotate all of the images randomly and generate an augmented dataset with multiple rotations for each initial image.\n",
    "\n",
    "Data can be *numerical* or *categorical*. For numerical data we may need to scale or shift the data. For categorical data we may need to encode it properly for our methods. For binary classes, we will usually encode the data with 0 or 1 values. For multiclass data, sometimes we can encode the classes using integer values (0, 1, 2, etc.) But sometimes we will need to use *one-hot* encoding, where multiple classes are encoded as a set of \"dummy\" binary variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f26049-8185-40cc-8b19-8d9e79891ce4",
   "metadata": {},
   "source": [
    "#### Step 3. Exploratory data analysis\n",
    "\n",
    "This is a very useful step whenever you are starting machine learning with a new dataset. We can use various techniques to summarize and visualize our data so as to gain an initial understanding of the data. This will help us to identify issues that will require additional data preparation (so back to step 2), and to select the best methods to use for the rest of the protocol.\n",
    "\n",
    "For example, we might examine correlations between features and between target values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30bdf6c-613e-48db-9acc-e19dd12b74c7",
   "metadata": {},
   "source": [
    "#### Step 4. Feature selection and extraction\n",
    "\n",
    "Each sample in our data will be represented with one or more *features*. Sometimes we can use the raw data as the features, but in most cases we need to do at least some processing of the data to generate the features needed for machine learning.\n",
    "\n",
    "Features may be numerical or categorical. The features describe our data samples and will be used as input for machine learning. We represent each sample as a feature vector, with each element of the vector being one of the features.\n",
    "\n",
    "Sometimes calculating the features may be a time-consuming step. Or we may need to do some preliminary work to identify the appropriate features. Or we may even need to perform feature engineering, creating new features to best describe our data as input to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ad2c2-834f-4c86-924c-b644dd4da9ad",
   "metadata": {},
   "source": [
    "#### Step 5. Creating training, validation and test sets\n",
    "\n",
    "This is a key step that will help us determine if our model has good *generalizability*, i.e. how good the model will be at predicting new or unseen data.\n",
    "\n",
    "To do this, we divide our data into training and test sets. We use the training set to find the best parameters for our model. We use the test set to evaluate how good the model actually is. When reporting the performance (e.g. accuracy) of the model it is important to use only the test set.\n",
    "\n",
    "One common pitfall in machine learning is to learn too much about the training set, and to have low generalizability. This is called *overfitting*. By evaluating the model performance on a test set we can determine the extent of *overfitting*.\n",
    "\n",
    "Often we will further divide the training set into a training set and a validation set. The validation set will be used to select _hyperparameters_ (see below), depending on the particular model we are using.\n",
    "\n",
    "We need to select the size of the sets. For example a common division is to put 80% of the data in the training set and 20% in the test set.\n",
    "\n",
    "The simplest method to generate these sets is to just divide the data randomly. But sometimes we need to be smarter when dividing the sets. For example, we might need to ensure that there are about the same proportion of positive and negative samples in each set.\n",
    "\n",
    "Even if we stratify our test set, it is not guaranteed that it is representative and the performance may vary every time we create a different split. A more robust technique is to perform _cross-validation_, where we split the data into $k$ groups (folds), and each fold will be used to measure performance exactly once, while remaining data are used to fit the model. Average performance over the $k$ folds will be much more robust. If there are no hyperparameters to tune, cross-validation can be used directly to measure the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dde4333-af81-4b08-b2ed-efc0ae97464b",
   "metadata": {},
   "source": [
    "#### Step 6. Select model type\n",
    "\n",
    "There are many different type of models available for both classification and regression problems. We will cover a few of them during the course!\n",
    "\n",
    "Each model describes a functional form and some *parameters* (or *weights*). We will then apply an optimization algorithm that will determine the best parameters for our training set. The models can vary between very simple linear models with one or two parameters, all the way to complicated *neural networks* with thousands or even billions of parameters!\n",
    "\n",
    "For simpler models, we can often select and configure the model with one line of code. On the other hand, for neural networks, we will create a complicated architecture consisting of many layers. We will cover neural networks in the second half of the course.\n",
    "\n",
    "We will sometimes distinguish *hyperparameters* from other types of parameters. The distinction is just that hyperparameters are parameters that aren't optimized by our optimization algorithm. For example, when we do polynomial regression in scikit-learn, the coefficients will be the parameters, and the degree of the polynomial will be a hyperparameter. We can use methods such as grid search to find the best hyperparameters.\n",
    "\n",
    "The *loss function* describes what the optimization algorithm is trying to minimize. For many types of models, the loss function is implicit (such as sum of squared errors for linear regression), but for neural networks we'll specify a loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d4895d-51a4-4673-a8b1-2c17f5b1c020",
   "metadata": {},
   "source": [
    "#### Step 7. Fit the model\n",
    "\n",
    "We run our optimization algorithm and find the parameters.\n",
    "\n",
    "The type of optimization algorithm to find the best parameters will depend on the type of model and our data. For example, when fitting a neural network, we will use a variant of a gradient descent algorithm. We also need to consider the time and computer resources that will be necessary for training. When we study training neural networks, we will need to consider training batches and training rates.\n",
    "\n",
    "For most of our examples, this will only take a split second, but in some cases some serious computational power and time will be required!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889af032-c793-4737-9239-50cd04f7b3d7",
   "metadata": {},
   "source": [
    "### Step 8. Evaluate the model\n",
    "\n",
    "This is actually the most important step. We have multiple metrics that we can use to evaluate the performance of the model and to compare different models. \n",
    "\n",
    "There are many different performance metrics that will appropriate for different kinds of problems. For classification problems, we will use accuracy but also additional metrics to help minimize false positives and false negatives. For regression problems we will $R^2$ or RMSE.\n",
    "\n",
    "Of course, in a real project we will need to go back and repeat the steps as many times as necessary until we have a model that is suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4c243-3de7-447e-8594-8d8af1ba430e",
   "metadata": {},
   "source": [
    "### Comic time\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/machine_learning.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10210c-0a58-4851-9c9a-b483e2aa4cce",
   "metadata": {},
   "source": [
    "### Mathematical notation\n",
    "\n",
    "Sometimes we will use mathematical to describe machine learning\n",
    "\n",
    "Each sample is characterised by a $D$-dimensional feature vector $\\overline{x}$\n",
    "\n",
    "$\\overline{x} = (x_1, ... X_D)^T$\n",
    "\n",
    "Model $f$ returns predicted targets $\\hat{y}$\n",
    "\n",
    "$\\hat{y} = f(\\overline{x})$\n",
    "\n",
    "Consider $N$ training samples $\\overline{x}_1, ..., \\overline{x}_N$\n",
    "\n",
    "The features are represented by data matrix $X$\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/FeatureMatrix.png\" width = \"200\">\n",
    "\n",
    "And in supervised learning, the output is a target vector $\\overline{y}$ of dimension $N$\n",
    "\n",
    "$\\overline{y} = (y_1, ... y_D)^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f73001-5376-4fce-bfb8-394f6ecee82a",
   "metadata": {},
   "source": [
    "## 3. What are some of the challenges and issues we need to consider when doing machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4b706-760c-4059-a215-2fb2c86807b4",
   "metadata": {},
   "source": [
    "### Traditional modeling vs machine learning\n",
    "\n",
    "You can think of traditional scientific modeling like cooking with a recipe. We know exactly what ingredients go in, and we can predict what will come out, just like we use equations to predict results in our models.\n",
    "\n",
    "On the other hand, machine learning is more like a magical cooking pot. We understand the basic idea - that the pot learns from what we've cooked before to make new dishes. But the exciting part is, we don't always know exactly what the pot will whip up next, or why it chose to add a pinch of this or a sprinkle of that (this is often called a 'black box model').\n",
    "\n",
    "Traditional science uses 'white box' models, where we know exactly how the inputs become outputs, like using a set formula. On the other hand, machine learning is more of a 'black box' model. We know the machine is learning, but we don't always understand the hows and whys of what it learns. This mystery is sometimes seen as a drawback of machine learning.\n",
    "\n",
    "Some folks might not like the mystery pot method, arguing that not fully understanding the process could be a problem. But hey, it's also part of what makes machine learning so intriguing!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc1004-5c40-4a6e-93f0-eaf32be53e93",
   "metadata": {},
   "source": [
    "### Overfitting\n",
    "\n",
    "This is one of the biggest challenges with machine learning. It is actually rather easy to train a model that has extremely high accuracy on the training data. But this isn't our goal: we want a model that is good at predictions on new or unseen data.\n",
    "\n",
    "What is happening is that the model is just learning about noise in the training set, instead of learning useful information about the data.\n",
    "\n",
    "Our main weapon against overfitting is to split our data into a training set and test set. When evaluating the performance of the trained model, if it is higher on the training set and lower on the test set, we are overfitting.\n",
    "\n",
    "Even better than using a test set, sometimes we will have the opportunity to test the model on actual new data, which is very useful for evaluating its true performance.\n",
    "\n",
    "Overfitting is particularly a problem when your model has a large number of parameters, for example with a large neural network. Often it is a better to use a simpler model with fewer parameters.s\n",
    "\n",
    "The converse, underfitting, is also possible, but it generally less of an issue; it is pretty easy to use a more complicated model with more parameters!\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/sphx_glr_plot_underfitting_overfitting_001.png\" width = \"1000\">\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7462650-a2ca-4d3e-ad27-2ed0fc30c8f6",
   "metadata": {},
   "source": [
    "### Handling outliers\n",
    "\n",
    "Often a dataset will contain some extreme values for certain features or targets. \n",
    "\n",
    "Sometimes outliers are erroneous (or missing) values. If we believe this to be the case, it is usually best to exclude the outliers from the data.\n",
    "\n",
    "Be very cautious when excluding outliers, since they can often have information about the true variability of the data.\n",
    "\n",
    "Remember, you can almost always improve the performance of the model by excluding outliers, but you may end up with a model that is less useful on real data.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/outlier1.png' width=300px align=\"right\">\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/SirTurtle/ML-BME-UofA-imgs/main/Week-2-Introduction-to-machine-learning/imgs/outlier2.png' width=300px align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cf1360-3954-40b0-958f-e88bf596c1ca",
   "metadata": {},
   "source": [
    "### Handling missing or invalid data\n",
    "\n",
    "It is common for datasets to contain some missing or invalid datapoints. For example, for patient data, not all the same tests may have been performed on every patient. There may also have been a mistake with the measurement or errors in data entry.\n",
    "\n",
    "We have multiple options to handle this situation:\n",
    "\n",
    "1. Remove samples with missing or invalid values. If there are only a few samples with these issues, removing those samples is usually the best solution.\n",
    "2. Replace the missing or invalid values with a default value. This is called *imputing* the values. For example, if we are missing a feature for some of the samples, we could calculate the median value of the rest of the dataset, and assign that value. We could even do machine learning to try to predict the missing values.\n",
    "\n",
    "Most of the example datasets will use won't have these issues. But almost every real world dataset will!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a95301-0932-4e07-9f95-6759d1199944",
   "metadata": {},
   "source": [
    "### Dimensionality reduction: PCA & ICA\n",
    "\n",
    "The aim of dimensionality reduction is to reduce the number of features (dimension of the feature vector) while preserving the important distinguishing characteristics of samples. This can be used to help visualize the structure of the dataset or can be used to fit the data to a lower-dimensional feature set.\n",
    "\n",
    "Modern healthcare data sets are extremely high-dimensional. It is not uncommon for data sets to have many more features than examples. With increasing dimensions the same amount of data fills the space more and more sparsely. This increases the possibility of finding a separating hyperplane by chance.\n",
    "\n",
    "More features = more parameters = greater chance of overfitting\n",
    "\n",
    "There are two methods commonly used here:\n",
    "\n",
    "- Principal Component Analysis (PCA)\n",
    "- Independent Component Analysis (ICA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5392727f-debf-4d5f-b04b-a6505dd5e66a",
   "metadata": {},
   "source": [
    "## 4. What are some of the biomedical applications of machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16258b2c-1cd5-42aa-8e28-94e88a125413",
   "metadata": {},
   "source": [
    "There are many biomedical applications of machine learning:\n",
    "\n",
    "- *Diagnostic* In this case we are interested in predicting if a patient is likely to have a disease condition, based on information about the patient.\n",
    "- *Prognostic* In this case we want to predict the likely progress or survival of a patient.\n",
    "- *Treatment* Here we want to predict the best treatment option.\n",
    "- *Drug discovery* Machine learning has many applications to drug discovery. It can be used to predict the activity of a chemical compound, toxicity, and pharmacokinetic properties.\n",
    "\n",
    "Here are some specific example datasets we'll use during this course:\n",
    "\n",
    "- Neonatal brain volumes. With this dataset we are interested in the relation between brain volumes and gestational ages for premature babies\n",
    "- Heart disease. With this dataset we are interested in predicting if the patient has heart disease and the seriousness of the disease based on measurements of heart function\n",
    "- MRI images.\n",
    "- And many others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
