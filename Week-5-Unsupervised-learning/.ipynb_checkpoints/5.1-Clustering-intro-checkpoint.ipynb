{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c4a677-a8ca-4bab-b6dd-c9155bad3861",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f8b983-4ffe-4562-81d2-0790566eb6b7",
   "metadata": {},
   "source": [
    "## Application: Breast Cancer Diagnosis\n",
    "\n",
    "<img src=\"imgs/Biopsy1.gif\" width = \"200\" style=\"float: right;\">\n",
    "\n",
    "Wisconsin breast cancer dataset\n",
    "- Cells extracted through a fine needle aspirate (a type of biopsy)\n",
    "- A digitised photograph through a microscope\n",
    "- Cells boundaries are detected interactively using snakes\n",
    "- Various features of the cells are extracted\n",
    "\n",
    "<img src=\"imgs/Biopsy2.png\" width = \"200\" style=\"float: right;\">\n",
    "\n",
    "30 features available \n",
    "- Radius: mean of distances from center to points on the perimeter\n",
    "- Texture: standard deviation of the intensities of the cell\n",
    "- Area: number of pixel within the cell boundary\n",
    "- Statistics for the cells in each biopsy specimen: mean value, standard error, worst (largest) value\n",
    "\n",
    "Diagnosis available: malignant/benign\n",
    "\n",
    "Street et al.: Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993\n",
    "\n",
    "We will first look at Wisconsin breast cancer dataset. Cells from healthy and\n",
    "malignant tissues were extracted using biopsy, and photographed through a\n",
    "microscope. The cells in these images were then segmented semi automatically using\n",
    "a method called snakes. Once the boundaries of the cells were found, these were\n",
    "used to calculate cell features, such as mean radius, area and texture. Statistics were\n",
    "calculated about the cells in each specimen, such as mean, standard error and the\n",
    "extreme value. This is an example of traditional hand crafted feature extraction from\n",
    "the images. The most modern algorithms now learn relevant features from images\n",
    "using convolutional neural networks. We also have ground truth labels with diagnosis\n",
    "of cancer, but in this lecture we will primarily focus in discovering underlying\n",
    "structure in the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3757cb1-dd70-4824-bfaf-63e62e1cc37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15888af8-1aec-41f6-a095-41f847f42229",
   "metadata": {},
   "source": [
    "## K-means clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3443cf4-b64a-4fb9-8fd1-e529d39b6f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
