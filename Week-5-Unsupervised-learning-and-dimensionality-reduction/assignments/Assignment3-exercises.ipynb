{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730295f5-4859-418d-8b53-96939ba5c510",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "# Regression and clustering exercises\n",
    "\n",
    "## Deadline: Thursday, October 26 at 8:00 PM\n",
    "## The assignment must be submitted in the form of a Jupyter notebook and uploaded to eClass.\n",
    "\n",
    "## Marks:\n",
    "- Part 1. Regression. 5 marks.\n",
    "- Part 2. Clustering. 5 marks.\n",
    "- Total = 10 marks.\n",
    "\n",
    "## Notes:\n",
    "Some partial code is provided; your solution should use that partial code. The solution doesn't need to be pretty! Make sure the code runs without errors. All required imports will be provided for you; you shouldn't import any other modules. You may need to check with the documentation for Python or Scikit-Learn, or other online sources. There are multiple solutions for most tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944810c5-c91c-43f7-b6c2-c211a99c1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584ddffb-1aa7-4150-92a2-9be315be68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will download the required data files from GitHub\n",
    "def download_data(source, dest):\n",
    "    base_url = 'https://raw.githubusercontent.com/'\n",
    "    owner = 'MaralAminpour'\n",
    "    repo = 'ML-BME-Course-UofA-Fall-2023'\n",
    "    branch = 'main'\n",
    "    url = '{}/{}/{}/{}/{}'.format(base_url, owner, repo, branch, source)\n",
    "    r = requests.get(url)\n",
    "    f = open(dest, 'wb')\n",
    "    f.write(r.content)\n",
    "    f.close()\n",
    "\n",
    "# Create the temp directory, if it doesn't already exist\n",
    "if not os.path.exists('temp'):\n",
    "   os.makedirs('temp')\n",
    "\n",
    "download_data('Assignments/data/GA-brain-volumes-1-feature.csv', 'temp/GA-brain-volumes-1-feature.csv')\n",
    "download_data('Assignments/data/GA-brain-volumes-6-features.csv', 'temp/GA-brain-volumes-6-features.csv')\n",
    "download_data('Assignments/data/GA-brain-volumes-86-features.csv', 'temp/GA-brain-volumes-86-features.csv')\n",
    "download_data('Assignments/data/slice.p', 'temp/slice.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246a3c33-7435-44f5-ae3b-62187e14210f",
   "metadata": {},
   "source": [
    "## Part 1. Regression\n",
    "## Compare the performance of linear regression models with different numbers of features \n",
    "\n",
    "In Part 1 of the assignment we will compare performance of multivariate linear regression models with different numbers of features to predict gestational age.\n",
    "\n",
    "First we will now load the three datasets (1-feature, 6-feature and 86-feature) and print out number of features. Run the code in the next two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aae8f46-8f03-460c-8829-0c648f4738e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create and return the feature matrix X and the target vector y\n",
    "def CreateFeaturesTargets(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    \n",
    "    # Convert from 'DataFrame' to numpy array\n",
    "    data = df.values\n",
    "\n",
    "    # Features are in columns one to end\n",
    "    X = data[:, 1:]\n",
    "    \n",
    "    # Scale features\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Labels are in the column zero\n",
    "    y = data[:, 0]\n",
    "\n",
    "    # Return Features and Labels\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f206ea-c099-452e-b344-58e8c0180840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets. Target values y are the same for all datasets\n",
    "X1, y = CreateFeaturesTargets('temp/GA-brain-volumes-1-feature.csv')\n",
    "print('Number of features in X1 is', X1.shape[1])\n",
    "\n",
    "X6, y = CreateFeaturesTargets('temp/GA-brain-volumes-6-features.csv')\n",
    "print('Number of features in X6 is', X6.shape[1])\n",
    "\n",
    "X86, y = CreateFeaturesTargets('temp/GA-brain-volumes-86-features.csv')\n",
    "print('Number of features in X86 is', X86.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa72bc-8fe3-43fb-ab83-b4f0c882fa5f",
   "metadata": {},
   "source": [
    "We will use this RMSE function. First, run the next code cell to define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f825c0c-3a01-4341-a045-eb7f958270bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(model,X,y):\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    print('RMSE: {} weeks'.format(round(rmse, 2)))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9498e94-fd08-457d-aac1-c2ae90f7fe46",
   "metadata": {},
   "source": [
    "In the next step we will create a linear regression model and calculate RMSE on the whole set. Use the function `RMSE` that we have created above.\n",
    "\n",
    "**Complete the code in the following cell to create a LinearRegression model object. Use the RMSE function to calculate and print the RMSE for each of the three datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb029b-5e0d-405b-9380-e77e9fbfe1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model\n",
    "# model = None\n",
    "\n",
    "# Single feature\n",
    "print('Single feature:')\n",
    "# rmse1 = None\n",
    "\n",
    "# 6 features\n",
    "print('Six features:')\n",
    "# rmse6 = None\n",
    "\n",
    "# 86 features\n",
    "print('86 features:')\n",
    "# rmse86 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094700f-b765-4a53-a6ec-71502f06f37d",
   "metadata": {},
   "source": [
    "**Question 1:** What happens with RMSE on the whole set as we increase the number of features? Can you interpret this behaviour?\n",
    "\n",
    "**Answer:** **Provide the text for your answer to Question 1 by editing this markdown cell.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac8e702-6344-49af-a5fd-b610b26fd110",
   "metadata": {},
   "source": [
    "We will use the RMSE_CV function. First, run the next code cell to define the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a2615-fb2a-4106-a7cb-55f55ee80f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE_CV(model,X,y):\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
    "    rmse_cv = np.sqrt(-np.mean(scores))\n",
    "    print('RMSE_CV: {} weeks'.format(round(rmse_cv,2)))\n",
    "    return rmse_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276e5dd6-b001-4d60-9ba6-a12e0800c582",
   "metadata": {},
   "source": [
    "Now let's calculate the cross-validated RMSE for the three different feature matrices.\n",
    "\n",
    "**Complete the code in the following cell. Use the RMSE_CV function that we created above to calculate and print the RMSE_CV for each of the three datasets. You will need to uncomment some lines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6185844e-9223-422e-9b85-ebaf96203c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single feature\n",
    "print('Single feature:')\n",
    "# rmse_cv1 = None\n",
    "\n",
    "# 6 features\n",
    "print('Six features:')\n",
    "# rmse_cv6 = None\n",
    "\n",
    "# 86 features\n",
    "print('86 features:')\n",
    "# rmse_cv86 = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b13cd-0a61-42f1-a5d9-146bc1a6141a",
   "metadata": {},
   "source": [
    "**Question 2:** Which model performs the best? Which model is overfitted? \n",
    "\n",
    "**Answer:** **Provide the text for your answer to Question 2 by editing this markdown cell.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d00a486-d366-4082-8648-d7a0f0c4fee2",
   "metadata": {},
   "source": [
    "## Part 2. Clustering\n",
    "\n",
    "### Explore Gaussian Mixture model\n",
    "\n",
    "In Part 2 of the assignment we will explore the theoretical concepts of Gaussian mixture models, including **likelihoods** and **posteriors**. We will re-use the `GaussianMixture` model that we fitted to perform segmentation of brain MRI in Notebook 5.2.\n",
    "\n",
    "First, run the following two code blocks to load the data and then to create a GaussianMixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf1bc1-ab65-439d-8b6b-4f6e0ac852bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MRI image data from a pickle file\n",
    "mri_slice = pickle.load(open('temp/slice.p', 'rb'))\n",
    "\n",
    "# Find indices of non-zero elements\n",
    "ind = np.where(mri_slice > 0)\n",
    "\n",
    "# Select non-zero elements\n",
    "slice2 = mri_slice[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294744e-e309-4a5f-bab0-4ae73ba05a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Create the GaussianMixture model\n",
    "model = GaussianMixture(n_components=3, random_state=42)\n",
    "\n",
    "# Create the feature matrix X by reshaping slice2 into 2D array\n",
    "X = slice2.reshape(-1, 1)\n",
    "\n",
    "# Fit the model and predict the cluster labels\n",
    "y_pred = model.fit_predict(X)\n",
    "\n",
    "# Create array of 2D labels:\n",
    "\n",
    "# Reshape the predicted labels to the original shape of mri_slice\n",
    "labels2D = np.zeros(mri_slice.shape)\n",
    "\n",
    "# Put the labels into fields with non-zero indices\n",
    "labels2D[ind] = y_pred + 1\n",
    "\n",
    "# Display the label image\n",
    "plt.imshow(labels2D)\n",
    "plt.set_cmap('plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af93935-ff4f-4bc9-8686-3c13a575892b",
   "metadata": {},
   "source": [
    "### Posterior probabilities\n",
    "\n",
    "Probabilistic segmentation $p_{ik}$ gives us probability that pixel $i$ to belong the class $k$. These are in fact **posterior probabilities** $$p(z_i=k|x_i, \\mu_k, \\sigma_k,c_k)$$ for the labels $z_i$ given the intensity value $x_i$ and parameters $\\mu_k, \\sigma_k,c_k$ of the Gaussian intensity distribution for class $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e5342-6b74-486c-be1b-eed85e893cca",
   "metadata": {},
   "source": [
    "**Task 2.1:** Now let's plot how posterior probability for each class varies with pixel intensity value.\n",
    "\n",
    "**Fill in the missing code below to display the probability curves. You will need to uncomment some lines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea0aff-739d-446b-a064-bc7a1a00ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel intensity value range\n",
    "intensity_range = np.linspace(0, np.max(slice2), 200)\n",
    "\n",
    "# Predict posterior probabilities for the intensity range\n",
    "# (Do not forget to reshape the intensity range to a 2D array for the prediction!)\n",
    "proba_curves = None\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize = [14, 10])\n",
    "\n",
    "# Plot normalised histogram\n",
    "# The normalisation is achieved by parameter density\n",
    "plt.subplot(211)\n",
    "plt.hist(slice2, bins=100, density=True)\n",
    "plt.title('Normalised Intensity Histogram')\n",
    "\n",
    "# Plot posterior probabilities in a for loop\n",
    "plt.subplot(212)\n",
    "# for i in range(0,3):\n",
    "#     plt.plot(None, None, linewidth=3, label='Class {}'.format(i))\n",
    "\n",
    "# Annotate the subplot\n",
    "plt.title('Posterior probabilities')\n",
    "plt.xlabel('intensity')\n",
    "plt.ylabel('posterior probability')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebf9dfd-fede-42bb-935c-94d6fa3e65d9",
   "metadata": {},
   "source": [
    "### Class-dependent likelihood\n",
    "\n",
    "Class-dependent likelihoods are modelled by Gaussian distributions scaled by the mixing proportions\n",
    "$$p(x_i|z_i=k,\\mu_k,\\sigma_k, c_k)=G(x_i,\\mu_k,\\sigma_k)c_k$$ \n",
    "\n",
    "To display these distributions over the normalised histogram (notice parameter `density=True`) we need to extract the `means_`, `covariances_` and `weights_` from the fitted `model`. Then we need to calculate the Gaussian distributions for these parameters. To do that we use function `norm.pdf` from `scipy.stats` module. Finally, these distributions need to be multiplied by the weights and plotted.\n",
    "\n",
    "**Task 2.2:** Plot the Gaussian intensity distributions for each class $k$ over the normalised image histogram. \n",
    "\n",
    "**To do that, fill in the missing code below and run the cell. You will need to uncomment some lines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f9afb-5e18-4cc6-9a60-9796c0f6fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate gaussian distribution use the norm.pdf function\n",
    "\n",
    "# Get parameters of GMM:\n",
    "# Means\n",
    "m = None  # Use flatten to make 1D arrays\n",
    "\n",
    "# Standard deviation\n",
    "s = None\n",
    "\n",
    "# Mixing proportions\n",
    "w = None\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize = [14,5])\n",
    "\n",
    "# Histogram\n",
    "# plt.hist(None, bins=100, None)\n",
    "\n",
    "# Class-dependent likelihoods - Gaussian PDFs\n",
    "for i in range(0,3):\n",
    "    likelihood = None\n",
    "    # plt.plot(intensity_range, likelihood, linewidth=3, label='Class {}'.format(i))\n",
    "plt.legend()\n",
    "plt.title('Class specific likelihood functions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72db98a-1797-4a95-8201-2ca54e5653f1",
   "metadata": {},
   "source": [
    "### Likelihood\n",
    "\n",
    "The likelihood for each pixel intensity $x_i$ given the Gaussian Mixture Model parameters $\\phi = (\\mu_k,\\sigma_k,c_k),k=1,...,K$ can be evaluated as\n",
    "$$p(x_i|\\phi)=\\sum_{k=1}^KG(x_i,\\mu_k,\\sigma_k)c_k $$\n",
    "\n",
    "We can calculate this function by adding the class-dependent likelihoods together. The alternative is to use a function provided by `GaussianMixture` model `score_samples` that returns **log-likelihood**.\n",
    "\n",
    "**Task 2.3:** Plot the likelihood function for the whole intensity range over the normalised image histogram. \n",
    "\n",
    "**To do that, first evaluate log-likelihood over the intensity range, then calculate the exponential using `np.exp` and then plot it. You will need to uncomment some lines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031cb36e-d427-4f14-a37d-8f8cbd2a6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare histogram with fitted Gaussian mixture likelihood function\n",
    "plt.figure(figsize=[14, 5])\n",
    "\n",
    "# Histogram\n",
    "# plt.hist(None, None, None)\n",
    "\n",
    "# Calculate likelihood\n",
    "likelihood = np.exp(model.score_samples(intensity_range.reshape(-1, 1)))\n",
    "\n",
    "# Plot likelihood\n",
    "# plt.plot(intensity_range, None, linewidth=3, c='k')\n",
    "plt.title('Fitted likelihood function')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
