{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression\n",
    "\n",
    "In this notebook we will look at **Multivariate Linear Regression** which seeks to fit the model\n",
    "\n",
    "$$y=w_0+w_1x_1+...+w_Dx_D$$\n",
    "\n",
    "where $(x_1,...,x_D)^T$ is the *feature vector*, $\\hat{y}$ is the *target value* and $(w_0,...,w_D)^T$ is the *weight vector* formed of parameters of the regression model that we seek to find.\n",
    "\n",
    "We will first investigate how it is implemented in `sklearn` and implement it ourselves in `numpy`. Then we will look at measuring the performance of regression methods and investigate how dimension of the feature vector influences the performance of the linear regression.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "<img src=\"pictures/BrainVolumes.png\" width = \"500\" style=\"float: right;\"> \n",
    "The biomedical application that we will investigate in this notebook is prediction of gestational age (GA) at scan from volumes of brain structures. The brain volumes come from the **Developing Human Connectomme Project** (dHCP, www.developingconnectome.org). We will use three different feature vectors:\n",
    "* **Whole brain volume - a single feature** \n",
    "* **Main brain structures - six features:** cortical gray matter, cortical white matter, myelinated subcortical white matter, subcortical gray matter, cerebellum and brainstem. \n",
    "* **All dHCP brain structures - 86 features** \n",
    "\n",
    "The segmentations were performed using dHCP processing pipeline (www.doi.org/10.1016/j.neuroimage.2018.01.054). The software is available for download here: www.github.com/MIRTK/DrawEM. The list of all labels is available here:www.github.com/MIRTK/DrawEM/blob/master/label_names/all_labels.csv. Please note we have excluded label 84. \n",
    "\n",
    "This notebook accompanies the **Part I and II** of the Lecture 3 **Regression**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression in Scikit-learn\n",
    "\n",
    "### Load the dataset\n",
    "\n",
    "We will first explore the multivariate linear regression using the dataset with 6 brain volumes for prediction of GA at scan. \n",
    "\n",
    "The code bellow loads the dataset, extract the feature matrix and the target vector, and scales the features using `StandardScaler`. This is implemented in the function `CreateFeaturesTargets`, which accepts a 'csv' file as an input and returns extracted feature matrix `X` that contains the volumes and target vector `y`with GA. \n",
    "\n",
    "\n",
    "__Activity 1:__ Fill in the code to print out the numbers of sample and features and run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/GA-brain-volumes-6-features.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# return Features and Labels\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[0;32m---> 24\u001b[0m X,y \u001b[38;5;241m=\u001b[39m \u001b[43mCreateFeaturesTargets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatasets/GA-brain-volumes-6-features.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of samples is\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of features is\u001b[39m\u001b[38;5;124m'\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m, in \u001b[0;36mCreateFeaturesTargets\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mCreateFeaturesTargets\u001b[39m(filename):\n\u001b[0;32m----> 7\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# convert from 'DataFrame' to numpy array\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/GA-brain-volumes-6-features.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def CreateFeaturesTargets(filename):\n",
    "    \n",
    "    df = pd.read_csv(filename,header=None)\n",
    "    \n",
    "    # convert from 'DataFrame' to numpy array\n",
    "    data = df.values\n",
    "\n",
    "    # Features are in columns one to end\n",
    "    X = data[:,1:]\n",
    "    \n",
    "    # Scale features\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Labels are in the column zero\n",
    "    y = data[:,0]\n",
    "\n",
    "    # return Features and Labels\n",
    "    return X, y\n",
    "\n",
    "X,y = CreateFeaturesTargets('temp/GA-brain-volumes-6-features.csv')\n",
    "\n",
    "print('Number of samples is', X.shape[0])\n",
    "print('Number of features is', X.shape[1])\n",
    "print('Number of targets is', y.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the dataset\n",
    "Run the code bellow to visualise individual features of this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for i in range(6):\n",
    "        plt.subplot(2,3,i+1)\n",
    "        plt.scatter(X[:,i], y)\n",
    "        plt.xlabel('Scaled volumes')\n",
    "        plt.ylabel('GA at scan')\n",
    "        plt.title('Structure '+ str(i))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model using normal equation\n",
    "\n",
    "The code bellow fits the `LinearRegression` model to the data using **normal equation**. The performance is evaluated using the **Root Mean Squared Error** (RMSE). This is done first on the whole dataset using function `mean_squared_error` and then using cross-validation implemented by a sklearn function `cross_val_score`. Run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Choose the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Calculate RMSE on the whole set\n",
    "model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print('RMSE: {} weeks'.format(round(rmse,2)))\n",
    "\n",
    "# Calculate RMSE using cross-validation\n",
    "scores = cross_val_score(model,X,y, scoring='neg_mean_squared_error',cv=5)\n",
    "rmse_cv = np.sqrt(-np.mean(scores))\n",
    "print('RMSE_CV: {} weeks'.format(round(rmse_cv,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2:** Notice the RMSE. In which units is it? We calculate RMSE on the whole dataset and using cross-validation. Which one is larger? We will later compare these errors to other regression methods.\n",
    "\n",
    "**Answer:** The RMSE is in weeks and represents the average error in estimated age of the baby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit model using SGD\n",
    "We will now fit the model multivariate linear regression model using **stochastic gradient descent** implemented in `SGDRegressor`.\n",
    "\n",
    "**Activity 3:** In the previous cell you have seen how to calculate RMSE. Complete the functions\n",
    "* `RMSE` to calculate RMSE on the whole dataset\n",
    "* `RMSE_CV` to calculate cross-validated RMSE \n",
    "\n",
    "Run the code and compare the error to the fit using normal equation, that we have perfored before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(model,X,y):\n",
    "    model.fit(X,y)\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    print('RMSE: {} weeks'.format(round(rmse,2)))\n",
    "    return rmse\n",
    "\n",
    "def RMSE_CV(model,X,y):\n",
    "    scores = cross_val_score(model,X,y, scoring='neg_mean_squared_error',cv=5)\n",
    "    rmse_cv = np.sqrt(-np.mean(scores))\n",
    "    print('RMSE_CV: {} weeks'.format(round(rmse_cv,2)))\n",
    "    return rmse_cv\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model = SGDRegressor(loss=\"squared_loss\", penalty=None)\n",
    "rmse = RMSE(model,X,y)\n",
    "rmse_cv = RMSE_CV(model,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Normal equation in Numpy\n",
    "\n",
    "Implement multivariate linear regression using the **normal equation** in `numpy`. Do __not__ use any `sklearn` functions.\n",
    "\n",
    "Perform the following steps:\n",
    "* Split the dataset into training and test set, by including the first 120 samples in the training set and the rest in the test set \n",
    "* Implement fitting of the model to the training data in `numpy` using $\\mathbf{w} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$\n",
    "* Predict the target values on the test according to $\\mathbf{\\hat{y}}=\\mathbf{Xw}$\n",
    "* Calculate the RMSE on the test set using $RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N(y_i-\\hat{y}_i)^2}$\n",
    "\n",
    "You will need these `numpy` functions:\n",
    "* `np.hstack` to concatenate two numpy arrays\n",
    "* `np.matmul` performs matrix multiplication\n",
    "* `matrix.T` transposes the `matrix`\n",
    "* `np.linalg.inv` inverts a matrix\n",
    "\n",
    "Some of the code has been provided for you, fill in the missing commands. You can refer to the Part I of lecture to help you complete this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column of ones\n",
    "x0 = np.ones([X.shape[0],1])\n",
    "\n",
    "# Concatenate with the feature matrix to add feature zero\n",
    "X1 = np.hstack([x0,X])\n",
    "\n",
    "# Print the first three lines of the new feature matrix\n",
    "print(np.around(X1[:3,:],2))\n",
    "\n",
    "# Print the new number of features\n",
    "print('\\n The new number of features is ', X1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test set\n",
    "X1_train = X1[:120,:]\n",
    "y_train = y[:120]\n",
    "X1_test = X1[120:,:]\n",
    "y_test = y[120:]\n",
    "print('Number of samples in train {} and test {}'.format(X1_train.shape[0],X1_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement equation w=(XtX)^-1 * Xty\n",
    "XtX = np.matmul(X1_train.T,X1_train)\n",
    "Xty = np.matmul(X1_train.T,y_train)\n",
    "w = np.matmul(np.linalg.inv(XtX),Xty)\n",
    "print('Coeffs:',np.around(w,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "y_pred_test = np.matmul(X1_test,w)\n",
    "\n",
    "# plot predicted against expected target values\n",
    "plt.scatter(y_test,y_pred_test, label = 'target values')\n",
    "plt.plot([28,44],[28,44],'r', label = '$y=\\hat{y}$')\n",
    "plt.title('Predictions on test set')\n",
    "plt.xlabel('Target values')\n",
    "plt.ylabel('Predicted target values')\n",
    "_=plt.legend(fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE on test set\n",
    "rmse = np.sqrt(np.mean((y_test-y_pred_test)**2))\n",
    "print('RMSE test: {} weeks'.format(round(rmse,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Compare performance of linear regression models with different numbers of features \n",
    "\n",
    "In this exercise we will compare performance of multivariate linear regression models with different numbers of features to predidict age of a baby.\n",
    "\n",
    "First we will now load the datasets and print out number of features. Run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets. Target values y  are the same for all datasets\n",
    "X1,y = CreateFeaturesTargets('datasets/GA-brain-volumes-1-feature.csv')\n",
    "print('Number of features in X1 is ', X1.shape[1])\n",
    "X6,y = CreateFeaturesTargets('datasets/GA-brain-volumes-6-features.csv')\n",
    "print('Number of features in X6 is ', X6.shape[1])\n",
    "X86,y = CreateFeaturesTargets('datasets/GA-brain-volumes-86-features.csv')\n",
    "print('Number of features in X86 is ', X86.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we will create a linear regression model and calculate RMSE on the whole set. Use the function `RMSE` that we have created previously. Fill in the code bellow and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Single feature\n",
    "print('Single feature:')\n",
    "rmse1 = RMSE(model,X1,y)\n",
    "\n",
    "# 6 features\n",
    "print('Six features:')\n",
    "rmse6 = RMSE(model,X6,y)\n",
    "\n",
    "# 86 features\n",
    "print('86 features:')\n",
    "rmse86 = RMSE(model,X86,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens with RMSE on the whole set as we increase the number of features? Can you interpret this behaviour?\n",
    "\n",
    "__Answer:__ RMSE increases with increasing number of features. This can be due to improvement of the fit but also due to overfitting. To recognise the overfitting we need to calculate RMSE using cross-validatation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the cross-validated RMSE for the three different feature matrices. You can use function `RMSE_CV` that we created before to calculate and print out the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single feature\n",
    "print('Single feature:')\n",
    "rmse_cv1 = RMSE_CV(model,X1,y)\n",
    "\n",
    "# 6 features\n",
    "print('Six features:')\n",
    "rmse_cv6 = RMSE_CV(model,X6,y)\n",
    "\n",
    "# 86 features\n",
    "print('86 features:')\n",
    "rmse_cv86 = RMSE_CV(model,X86,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model performs the best? Which model is overfitted? \n",
    "\n",
    "__Answer:__ The model with 6 features performs the best, because it has the lowest RMSE_CV=1.27. The model with 86 features has RMSE=0.69 and RMSE_CV=2.08 which is a big difference and it is therefore clearly overfitted."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
